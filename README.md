# LLM Information Extraction Workshop

ðŸš€ **Learn to extract structured information with LLMs locally and at scale on CESGA GPUs.**

This hands-on workshop teaches you how to run LLMs with **Ollama**, design effective prompts, validate outputs with **Pydantic**, and execute remote batch jobs on the **CESGA FinisTerrae III cluster**.

---

## ðŸŽ¯ Learning Outcomes

By the end of this workshop, you will:

- âœ… Run and interact with LLMs locally using **Ollama**.
- âœ… Design and test prompts to extract structured information.
- âœ… Parse and validate responses programmatically.
- âœ… Run batch jobs on CESGAâ€™s GPU cluster.

---

## ðŸ“‹ Prerequisites

- Basic knowledge of Python programming.
- Familiarity with command-line operations.
- Modules 1â€“3 can be done locally; Module 4 requires CESGA FinisTerrae III access.

---

## ðŸš€ Quick Start

1. **[Module 1](01_setup/)** â€“ Set up Ollama locally and configure CESGA access.
2. **[Module 2](02_basic_llm_extraction/)** â€“ Run your first extraction jobs with Ollama.
3. **[Module 3](03_structured_llm_extraction/)** â€“ Validate and save structured outputs.
4. **[Module 4](04_cluster_execution/)** â€“ Run your scripts on CESGA GPUs.

---

## ðŸ“‚ Repository Structure

| Folder                          | Description                             |
| ------------------------------- | --------------------------------------- |
| `01_setup/`                     | Local LLM setup and CESGA access        |
| `02_basic_llm_extraction/`      | Basic local LLM queries & batch jobs    |
| `03_structured_llm_extraction/` | Structured data extraction & validation |
| `04_cluster_execution/`         | CESGA cluster job scripts               |
| `data/`                         | Sample texts and outputs                |

---

## ðŸ”— Navigation

âž¡ **Start Here:** [Module 1 â€“ Setup & Environment](01_setup/README.md)
